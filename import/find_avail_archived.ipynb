{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find available caches\n",
    "\n",
    "We first need to see if any of the Twitter user pages have been cached by Internet Archive. We can do this by making a request to `http://archive.org/wayback/available?url=http://twitter.com/TWITTER_SCREEN_NAME_HERE`. This will return the url and timestamp of any caches made, if they exist.\n",
    "\n",
    "So we iterate through the list of twitter screen names, checking the Wayback API for any available caches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install internetarchive\n",
    "#!pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial = \"http://archive.org/wayback/available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through list of flagged twitter screen names\n",
    "with open('./data/twitter_handle_urls.csv') as f:\n",
    "    for line in f:\n",
    "        params = {'url': line}\n",
    "        r = requests.get(initial, params=params)\n",
    "        d = r.json()\n",
    "        #print(d)\n",
    "        items.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print URLs and timestamp of any available archives\n",
    "for item in items:\n",
    "    if 'archived_snapshots' in item:\n",
    "        if 'closest' in item['archived_snapshots']:\n",
    "            print(item['url'], item['archived_snapshots']['closest']['url'], item['archived_snapshots']['closest']['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write URL of any available archives to file\n",
    "with open('./data/avail_urls.txt', 'w') as f:\n",
    "    for item in items:\n",
    "        if 'archived_snapshots' in item:\n",
    "            if 'closest' in item['archived_snapshots']:\n",
    "                f.write(item['archived_snapshots']['closest']['url'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
